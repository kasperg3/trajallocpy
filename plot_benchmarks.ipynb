{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "ours_naive = \"benchmarks/AC300/ours_naive_1robots_infcapacity_AC300.csv\"\n",
    "ours = \"benchmarks/AC300/ours_1robots_infcapacity_AC300.csv\"\n",
    "ours_naive_2r = \"benchmarks/AC300/ours_naive_2robots_1200capacity_AC300.csv\"\n",
    "ours_2r = \"benchmarks/AC300/ours_2robots_1200capacity_AC300.csv\"\n",
    "ours_naive_4r = \"benchmarks/AC300/ours_naive_4robots_600capacity_AC300.csv\"\n",
    "ours_4r = \"benchmarks/AC300/ours_4robots_600capacity_AC300.csv\"\n",
    "# Create an empty list to hold the dataframes\n",
    "ours_naive_df = pd.read_csv(ours_naive)\n",
    "ours_df = pd.read_csv(ours)\n",
    "ours_naive_2r_df = pd.read_csv(ours_naive_2r)\n",
    "ours_2r_df = pd.read_csv(ours_2r)\n",
    "ours_naive_4r_df = pd.read_csv(ours_naive_4r)\n",
    "ours_4r_df = pd.read_csv(ours_4r)\n",
    "\n",
    "concatenated = pd.concat(\n",
    "    [\n",
    "        ours_naive_2r_df.assign(dataset=\"Point\").assign(n_robots=\"2 robots\"),\n",
    "        ours_2r_df.assign(dataset=\"Trajectory\").assign(n_robots=\"2 robots\"),\n",
    "    ]\n",
    ")\n",
    "sns.set_palette('muted')\n",
    "sns.scatterplot(data=concatenated, x=\"num_tasks\", y=\"totalRouteCosts\", hue=\"dataset\",palette=\"crest\")\n",
    "plt.xlabel('Number of tasks')\n",
    "plt.ylabel('Total travel time (s)')\n",
    "\n",
    "plt.legend( title=\"Estimation method\", loc=\"lower right\")\n",
    "plt.ylim(0)\n",
    "plt.savefig(\"point_vs_trajectory_scatter.png\")\n",
    "\n",
    "not_converged = concatenated[concatenated['iterations'] == 200]\n",
    "naive_not_converged = not_converged[not_converged['dataset'] == \"Point\"]\n",
    "ours_not_converged = not_converged[not_converged['dataset'] == \"Trajectory\"]\n",
    "\n",
    "print(\"naive not converged: \", len(naive_not_converged.index) / len(concatenated[concatenated['dataset'] == \"Point\"].index) * 100, \"%\" )\n",
    "print(\"ours not converged: \", len(ours_not_converged.index) / len(concatenated[concatenated['dataset'] == \"Trajectory\"].index) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours_naive_df = pd.read_csv(\"benchmarks/AC300/ours_naive_2robots_1200capacity_AC300.csv\")\n",
    "ours_naive_1r_df = pd.read_csv(\"benchmarks/AC300/ours_naive_1robots_infcapacity_AC300.csv\")\n",
    "ours_naive_4r_df = pd.read_csv(\"benchmarks/AC300/ours_naive_4robots_600capacity_AC300.csv\")\n",
    "ours_df = pd.read_csv(\"benchmarks/AC300/ours_2robots_1200capacity_AC300.csv\")\n",
    "ours_1r_df = pd.read_csv(\"benchmarks/AC300/ours_1robots_infcapacity_AC300.csv\")\n",
    "ours_4r_df = pd.read_csv(\"benchmarks/AC300/ours_4robots_600capacity_AC300.csv\")\n",
    "\n",
    "df1 = pd.concat(\n",
    "    [\n",
    "        ours_1r_df.assign(dataset=\"trajectory est.\").assign(n_robots=\"1 robot\"),\n",
    "        ours_df.assign(dataset=\"trajectory est.\").assign(n_robots=\"2 robots\"),\n",
    "        ours_4r_df.assign(dataset=\"trajectory est.\").assign(n_robots=\"4 robots\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df2 = pd.concat(\n",
    "    [\n",
    "        ours_naive_1r_df.assign(dataset=\"trajectory est.\").assign(n_robots=\"1 robot\"),\n",
    "        ours_naive_df.assign(dataset=\"trajectory est.\").assign(n_robots=\"2 robots\"),\n",
    "        ours_naive_4r_df.assign(dataset=\"trajectory est.\").assign(n_robots=\"4 robots\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combine the two DataFrames into one\n",
    "df = pd.concat([df1, df2], keys=['trajectory est.', 'point est.']).reset_index()\n",
    "\n",
    "# Divide the DataFrame into bins of size 5\n",
    "bins = range(20, 199, 20)\n",
    "labels = [f'{i}' for i in bins[:-1]]\n",
    "df['group'] = pd.cut(df['num_tasks'], bins=bins, labels=labels)\n",
    "\n",
    "# Create a pivot table to calculate the mean income for each age group and dataset\n",
    "pivot_df = pd.pivot_table(df, values='totalRouteCosts', index='group', columns='level_0', aggfunc='mean')\n",
    "\n",
    "# Create a stacked bar chart with error bars using seaborn\n",
    "\n",
    "sns.barplot(x=pivot_df.index, y=pivot_df['point est.'], color=(0.2823529411764706, 0.47058823529411764, 0.8156862745098039), label='point est.')\n",
    "sns.barplot(x=pivot_df.index, y=pivot_df['trajectory est.'], color=(0.9333333333333333, 0.5215686274509804, 0.2901960784313726), label='trajectory est.')\n",
    "\n",
    "plt.xlabel('Number of tasks')\n",
    "plt.ylabel('Mean of total travel time (s)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the performance increase between naive and ours\n",
    "print(\"ours: \",df2[\"totalRouteCosts\"].mean(),df2[\"totalRouteCosts\"].std()*100 /df2[\"totalRouteCosts\"].mean())\n",
    "print(\"ours: \",df1[\"totalRouteCosts\"].mean(),df1[\"totalRouteCosts\"].std()*100 / df1[\"totalRouteCosts\"].mean())\n",
    "\n",
    "print(\"Improvement over poiont: \", (df2[\"totalRouteCosts\"].mean()-df1[\"totalRouteCosts\"].mean())/df2[\"totalRouteCosts\"].mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours_naive = \"benchmarks/AC300/ours_naive_4robots_600capacity_AC300.csv\"\n",
    "ours = \"benchmarks/AC300/ours_4robots_600capacity_AC300.csv\"\n",
    "\n",
    "# Create an empty list to hold the dataframes\n",
    "ours_naive_df = pd.read_csv(ours_naive)\n",
    "ours_df = pd.read_csv(ours)\n",
    "\n",
    "concatenated = pd.concat([ours_naive_df.assign(dataset='point est.'), ours_df.assign(dataset='trajectory est.')])\n",
    "\n",
    "sns.scatterplot(data=concatenated, x=\"num_tasks\", y=\"totalRouteCosts\", hue=\"dataset\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ours_naive = \"benchmarks/ours_naive_4robots_600capacity_AC300.csv\"\n",
    "# ours = \"benchmarks/ours_4robots_600capacity_AC300.csv\"\n",
    "ours_naive = \"benchmarks/AC300/ours_naive_2robots_1200capacity_AC300.csv\"\n",
    "ours = \"benchmarks/AC300/ours_2robots_1200capacity_AC300.csv\"\n",
    "\n",
    "# Create an empty list to hold the dataframes\n",
    "ours_naive_df = pd.read_csv(ours_naive)\n",
    "ours_df = pd.read_csv(ours)\n",
    "\n",
    "concatenated = pd.concat([ours_naive_df.assign(dataset='point est.'), ours_df.assign(dataset='trajectory est.')])\n",
    "sns.set_palette('muted')\n",
    "\n",
    "plt.ylim(0, 100)\n",
    "sns.scatterplot(data=concatenated, x=\"num_tasks\", y=\"iterations\", hue=\"dataset\")\n",
    "\n",
    "# Merge the two DataFrames on the 'Key' column\n",
    "merged_df = pd.merge(ours_naive_df, ours_df, on='dataset_name', suffixes=('_ours', '_naive'))\n",
    "\n",
    "print(\"ours iteration mean\", ours_df[\"iterations\"].mean())\n",
    "print(\"ours iteration std\", ours_df[\"iterations\"].std())\n",
    "print(\"naive iteration mean\",ours_naive_df[\"iterations\"].mean())\n",
    "print(\"naive iteration std\",ours_naive_df[\"iterations\"].std())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ours_naive = \"benchmarks/AC300/ours_naive_2robots_1200capacity_AC300.csv\"\n",
    "ours = \"benchmarks/AC300/ours_2robots_1200capacity_AC300.csv\"\n",
    "ours_naive_4r = \"benchmarks/AC300/ours_naive_4robots_600capacity_AC300.csv\"\n",
    "ours_4r = \"benchmarks/AC300/ours_4robots_600capacity_AC300.csv\"\n",
    "# Create an empty list to hold the dataframes\n",
    "ours_naive_df = pd.read_csv(ours_naive)\n",
    "ours_df = pd.read_csv(ours)\n",
    "ours_naive_4r_df = pd.read_csv(ours_naive_4r)\n",
    "ours_4r_df = pd.read_csv(ours_4r)\n",
    "\n",
    "concatenated = pd.concat(\n",
    "    [\n",
    "        ours_naive_df.assign(dataset=\"point est.\").assign(n_robots=\"2 robots\"),\n",
    "        ours_df.assign(dataset=\"trajectory est.\").assign(n_robots=\"2 robots\"),\n",
    "        ours_naive_4r_df.assign(dataset=\"point est.\").assign(n_robots=\"4 robots\"),\n",
    "        ours_4r_df.assign(dataset=\"trajectory est.\").assign(n_robots=\"4 robots\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "sns.scatterplot(data=concatenated, x=\"num_tasks\", y=\"computeTime\", hue=\"dataset\", style=\"n_robots\")\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, 1000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compare the sum of the costs of all the routes with the routes generated by agarwal\n",
    "# BUT be 100% clear about the difference in colision checking\n",
    "two_robot_30_samples = pd.read_csv(\"benchmarks/VM25/ours_2robots_1200capacity_repeat30_VM25_13.csv\")\n",
    "three_robot_30_samples = pd.read_csv(\"benchmarks/VM25/ours_3robots_800capacity_repeat30_VM25_13.csv\")\n",
    "four_robot_30_samples = pd.read_csv(\"benchmarks/VM25/ours_4robots_480capacity_repeat30_VM25_13.csv\")\n",
    "five_robot_30_samples = pd.read_csv(\"benchmarks/VM25/ours_5robots_400capacity_repeat30_VM25_13.csv\")\n",
    "eight_robot_30_samples = pd.read_csv(\"benchmarks/VM25/ours_8robots_400capacity_repeat30_VM25_13.csv\")\n",
    "\n",
    "concatenated = pd.concat(\n",
    "    [\n",
    "        two_robot_30_samples[two_robot_30_samples['iterations'] != 200],\n",
    "        three_robot_30_samples[three_robot_30_samples['iterations'] != 200],\n",
    "        four_robot_30_samples[four_robot_30_samples['iterations'] != 200],\n",
    "        five_robot_30_samples[five_robot_30_samples['iterations'] != 200],\n",
    "        eight_robot_30_samples[eight_robot_30_samples['iterations'] != 200],\n",
    "    ]\n",
    ")\n",
    "sns.set_palette('muted')\n",
    "\n",
    "fig = sns.boxplot(data=concatenated,x=\"number_of_agents\", y=\"iterations\")\n",
    "fig.set(xlabel='Number of agents', ylabel='Number of iterations')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compare the sum of the costs of all the routes with the routes generated by agarwal\n",
    "# BUT be 100% clear about the difference in colision checking\n",
    "vm25_13_sota = pd.read_csv(\"benchmarks/VM25/agarwal_vm25_13.csv\")\n",
    "ours_vm25_13_1robot = pd.read_csv(\"benchmarks/VM25/ours_1robots_1600capacity_repeat30_VM25_13.csv\")\n",
    "ours_vm25_13_2robot = pd.read_csv(\"benchmarks/VM25/ours_2robots_1200capacity_repeat30_VM25_13.csv\")\n",
    "ours_vm25_13_3robot = pd.read_csv(\"benchmarks/VM25/ours_3robots_800capacity_repeat30_VM25_13.csv\")\n",
    "ours_vm25_13_4robot = pd.read_csv(\"benchmarks/VM25/ours_4robots_480capacity_repeat30_VM25_13.csv\")\n",
    "ours_vm25_13_5robot = pd.read_csv(\"benchmarks/VM25/ours_5robots_400capacity_repeat30_VM25_13.csv\")\n",
    "r1_mean = ours_vm25_13_1robot['totalRouteLength'].mean()\n",
    "r1_std = ours_vm25_13_1robot['totalRouteLength'].std()\n",
    "r2_mean =ours_vm25_13_2robot[ours_vm25_13_2robot['iterations'] != 200]['totalRouteLength'].mean()\n",
    "r2_std = ours_vm25_13_2robot[ours_vm25_13_2robot['iterations'] != 200]['totalRouteLength'].std()\n",
    "r3_mean =ours_vm25_13_3robot[ours_vm25_13_3robot['iterations'] != 200]['totalRouteLength'].mean()\n",
    "r3_std = ours_vm25_13_3robot[ours_vm25_13_3robot['iterations'] != 200]['totalRouteLength'].std()\n",
    "r4_mean = ours_vm25_13_4robot[ours_vm25_13_4robot['iterations'] != 200]['totalRouteLength'].mean()\n",
    "r4_std = ours_vm25_13_4robot[ours_vm25_13_4robot['iterations'] != 200]['totalRouteLength'].std()\n",
    "r5_mean = ours_vm25_13_5robot[ours_vm25_13_5robot['iterations'] != 200]['totalRouteLength'].mean()\n",
    "r5_std = ours_vm25_13_5robot[ours_vm25_13_5robot['iterations'] != 200]['totalRouteLength'].std()\n",
    "print(\"r1 mean: \", r1_mean,\" within state of the art: \", (vm25_13_sota[\"Sum of Costs of Routes\"][0] - r1_mean) / vm25_13_sota[\"Sum of Costs of Routes\"][0] * 100, \" with \", r1_std/r1_mean * 100 ,\"% confidence\")\n",
    "print(\"r2 mean: \", r2_mean,\" within state of the art: \", (vm25_13_sota[\"Sum of Costs of Routes\"][1] - r2_mean) / vm25_13_sota[\"Sum of Costs of Routes\"][1] * 100, \" with \", r2_std/r2_mean * 100 ,\"% confidence\")\n",
    "print(\"r3 mean: \", r3_mean,\" within state of the art: \", (vm25_13_sota[\"Sum of Costs of Routes\"][2] - r3_mean) / vm25_13_sota[\"Sum of Costs of Routes\"][2] * 100, \" with \", r3_std/r3_mean * 100 ,\"% confidence\")\n",
    "print(\"r4 mean: \", r4_mean,\" within state of the art: \", (vm25_13_sota[\"Sum of Costs of Routes\"][3] - r4_mean) / vm25_13_sota[\"Sum of Costs of Routes\"][3] * 100, \" with \", r4_std/r4_mean * 100 ,\"% confidence\")\n",
    "print(\"r5 mean: \", r5_mean,\" within state of the art: \", (vm25_13_sota[\"Sum of Costs of Routes\"][4] - r5_mean) / vm25_13_sota[\"Sum of Costs of Routes\"][4] * 100, \" with \", r5_std/r5_mean * 100 ,\"% confidence\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max route cost comparrison\n",
    "\n",
    "Only routes containing 0 to 100 tasks have been used in this experiment. The agents have all been initialized at the same point and has to return to this point when finished. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "# Load the data\n",
    "ac300_1r = pd.read_csv(\"benchmarks/AC300/1agents_99999capacity_AC300.csv\")\n",
    "ac300_2r = pd.read_csv(\"benchmarks/AC300/2robots_1500capacity_AC300.csv\")\n",
    "ac300_4r = pd.read_csv(\"benchmarks/AC300/4robots_750capacity_AC300.csv\")\n",
    "ac300_6r = pd.read_csv(\"benchmarks/AC300/6robots_500capacity_AC300.csv\")\n",
    "ac300_8r = pd.read_csv(\"benchmarks/AC300/8robots_500capacity_AC300.csv\")\n",
    "ac300_10r = pd.read_csv(\"benchmarks/AC300/10robots_500capacity_AC300.csv\")\n",
    "ac300_12r = pd.read_csv(\"benchmarks/AC300/12robots_500capacity_AC300.csv\")\n",
    "ac300_14r = pd.read_csv(\"benchmarks/AC300/14robots_500capacity_AC300.csv\")\n",
    "\n",
    "# # Load the point data\n",
    "ac300_2r_point = pd.read_csv(\"experiments/AC300_2agents_1500capacity_point_est.csv\")\n",
    "# ac300_4r_point = pd.read_csv(\"benchmarks/AC300/point_4robots_500capacity_AC300.csv\")\n",
    "# ac300_6r_point = pd.read_csv(\"benchmarks/AC300/point_6robots_400capacity_AC300.csv\")\n",
    "# ac300_8r_point = pd.read_csv(\"benchmarks/AC300/point_8robots_300capacity_AC300.csv\")\n",
    "# ac300_10r_point = pd.read_csv(\"benchmarks/AC300/point_10robots_200capacity_AC300.csv\")\n",
    "# ac300_12r_point = pd.read_csv(\"benchmarks/AC300/point_12robots_200capacity_AC300.csv\")\n",
    "# ac300_14r_point = pd.read_csv(\"benchmarks/AC300/point_14robots_200capacity_AC300.csv\")\n",
    "\n",
    "# point_concatenated =pd.concat([ac300_2r_point, ac300_4r_point, ac300_6r_point, ac300_8r_point, ac300_10r_point, ac300_12r_point,ac300_14r_point]) \n",
    "concatenated = pd.concat([ac300_2r, ac300_4r, ac300_6r, ac300_8r, ac300_10r, ac300_12r, ac300_14r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the highest route costs\n",
    "sns.scatterplot(data=concatenated, x=\"num_tasks\", y=\"maxRouteCost\", hue=\"number_of_agents\",palette=\"crest\")\n",
    "# sns.lineplot(data=concatenated, x=\"num_tasks\", y=\"maxRouteCost\", hue=\"number_of_agents\",palette=\"crest\")\n",
    "plt.ylim(0)\n",
    "plt.legend( title=\"Number of Agents\", loc=\"upper right\")\n",
    "plt.xlabel('Number of tasks')\n",
    "plt.ylabel('Makespan (s)')\n",
    "plt.savefig(\"highest_travel_time_scatter.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the total route cost\n",
    "sns.scatterplot(data=pd.concat([ac300_2r.assign(dataset='Trajectory'),ac300_2r_point.assign(dataset='Point')]), x=\"num_tasks\", y=\"totalRouteCosts\", hue=\"dataset\",palette=\"crest\")\n",
    "plt.xlabel('Number of tasks')\n",
    "plt.ylabel('Total travel time (s)')\n",
    "plt.legend( title=\"Number of Agents\")\n",
    "plt.ylim(0)\n",
    "plt.savefig(\"total_route_cost_scatter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.boxplot(data=concatenated,x=\"number_of_agents\", y=\"iterations\",palette=\"crest\")\n",
    "plt.xlabel('Number of agents')\n",
    "plt.ylabel('Number of iterations')\n",
    "plt.savefig(\"iterations_agents_boxplot.svg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AC300 performance comparrison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the benchmark datasets from agarwal and bahnemann\n",
    "ac300_2r_agarwal = pd.read_csv(\"benchmarks/AC300/agarwal_AC300_1200_Capacity.csv\")\n",
    "ac300_bahnemann = pd.read_csv(\"benchmarks/AC300/bahnemann_coverage_results.csv\")\n",
    "\n",
    "ac300_1r_agarwal = pd.read_csv(\"benchmarks/AC300/agarwal_AC300_inf_Capacity.csv\")\n",
    "\n",
    "our_total_route_cost_2r = ac300_2r[\"totalRouteCosts\"].sum()\n",
    "our_total_route_cost_1r = ac300_1r[\"totalRouteCosts\"].sum()\n",
    "\n",
    "agarwal_total_route_cost_2r = ac300_2r_agarwal[\"Sum of Costs of Routes\"].sum()\n",
    "agarwal_total_route_cost_1r = ac300_1r_agarwal[\"Sum of Costs of Routes\"].sum()\n",
    "overhead_2r_cost_our_vs_agarwal = (our_total_route_cost_2r - agarwal_total_route_cost_2r) / our_total_route_cost_2r * 100\n",
    "overhead_1r_cost_our_vs_agarwal = (our_total_route_cost_1r - agarwal_total_route_cost_1r) / our_total_route_cost_1r * 100\n",
    "\n",
    "print(\"agarwal 2 robots :\" + \" Total route cost:\" + str(agarwal_total_route_cost_2r))\n",
    "print(\"our 2 robots :\" + \" Total route cost:\" + str(our_total_route_cost_2r))\n",
    "print(\"overhead cost 2r: \" + str(overhead_2r_cost_our_vs_agarwal))\n",
    "print(\"agarwal 1 robots :\" + \" Total route cost:\" + str(agarwal_total_route_cost_1r))\n",
    "print(\"our 1 robots :\" + \" Total route cost:\" + str(our_total_route_cost_1r))\n",
    "print(\"overhead cost 1r: \" + str(overhead_1r_cost_our_vs_agarwal))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
